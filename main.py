# End of degree thesis by Hugo GarcÃ­a Cuesta (100428954). Computer Engineering Grade, University Carlos III of Madrid

# IMPORTS
import json
import ogamus
import shutil
import sys
import numpy as np
from ai2thor.controller import Controller
from problem_definition import ProblemDefinition
from parser_ai2thor_pddl import ParserAI2THORPDDL
from parser_pddl_ai2thor import ParserPDDLAI2THOR
from planificador import Planificador
from exec_ogamus import ExecOgamus
from aux import printAgentStatus, printLastActionStatus, createCamera, printObjectStatus, removeResultFolders, isObjectOnScene

# CONSTANTS
DATASET = 'Datasets/test_set_ogn_ithor.json'
LOG = "Results/test_set_ogn_ithor_steps200/episode_0/log.txt"

# MAIN FLOW OF THE PROGRAM

# We clean the results folder before executing
removeResultFolders()

# User selects the method he wants to use.
    # 1. METADATA: uses data extracted from the simulator to get object positions and applies a automated planning in order to find the best plan to make an action in the environment
    # 2. OGAMUS: Uses the OGAMUS algorithm (credits in README). Scans the scene using pretrained models to find the desired objective and if the objective is found, it executes the action.
inputs = ProblemDefinition()
if len(sys.argv) == 1:
    method = inputs.method_selection()
else:
    method = "2"

# We ask the user to input the scene number he wants
    # [1-30] - Kitchens
    # [201-230] - Living rooms
    # [301-330] - Bedrooms
    # [401-430] - Bathrooms
scene_number = inputs.scene_selection()

# If method = 1 -> METADATA
if method == '1':

    # Initial start of the environment 
    print("*STARTING ENVIRONMENT*\n")
    controller = Controller(
                            agentMode="default", # Agent used is iTHOR -> default
                            visibilityDistance=1.5, # Visibility distance
                            scene="FloorPlan" + str(scene_number),
                            gridSize=0.25, # Step size
                            snapToGrid=True,
                            rotateStepDegrees=90,
                            renderDepthImage=False,
                            renderInstanceSegmentation=False,
                            width=300, # Controller width
                            height=300, # Controller height
                            fieldOfView=90 # Controller fiold of view
                            )
    
    # We create a camera on top of the scene and save an image
    createCamera(controller)

    print("*ENVIRONMENT SUCCESSFULLY STARTED*\n")

    # Loop that allows to repeat actions on the same environment
    iteration = 1
    loop = 'Y'
    while loop == 'Y':
        # Set up problem and output path
        problem_path, output_path = inputs.paths_selection(iteration)

        # Execution of an action inside the controller. GetReachablePositions allow us to get all the positions where the agent is allowed to be in the scene
        event = controller.step(action="GetReachablePositions")

        # Ask user for problem and objective
        problem, objective, liquid = inputs.problem_selection(event)

        # Using the parser, we translate the simulator state to a PDDL problem
        ParserAI2THORPDDL(event, problem_path, problem, objective, controller)

        # Execute the planner with the problem file generated and the corresponding domain (based on selected action)
        plan = Planificador(problem_path, output_path, problem, print=True, ogamus=False)

        # Parse and execute plan into actions
        parsed = ParserPDDLAI2THOR(plan.get_plan(), controller, iteration, liquid)

        # Final state visualization depending on the type of the problem
        printLastActionStatus(controller.last_event)
        if problem == 'move':
            printAgentStatus(controller.last_event)
        else:
            printObjectStatus(controller.last_event, objective)

        # Ask if the user wants to execute another action. If not, stop the program.
        loop = input('Do you want to execute another action? [Y/n]: ')
        iteration += 1


# If method = 2 -> OGAMUS
else:
    # Compute auxiliary params for OGAMUS execution
    hfov = 79 / 360. * 2. * np.pi
    vfov = 2. * np.arctan(np.tan(hfov / 2) * 224 / 224)
    vfov = np.rad2deg(vfov)

    # Controller start
    print("*STARTING ENVIRONMENT*\n")
    controller = Controller(
                            renderDepthImage=1,
                            renderObjectImage=True,
                            visibilityDistance=1,
                            gridSize=0.25,
                            rotateStepDegrees=45,
                            scene="FloorPlan" + str(scene_number),
                            continuousMode=True,
                            snapToGrid=False,
                            width=224,
                            height=224,
                            fieldOfView=vfov,
                            agentMode='default'
                            )

    # We create a camera on top of the scene and save an image
    createCamera(controller)

    # We get initial positions of the agent to pass it to OGAMUS
    event = controller.step("Pass")
    agent_pos = event.metadata["agent"]["position"]
    agent_rot = event.metadata["agent"]["rotation"]
    agent_hor = event.metadata["agent"]["cameraHorizon"]
    print("*ENVIRONMENT SUCCESSFULLY STARTED*\n")

    # Reads problems from CLI or arguments if a PDDL problem is passed.
    if len(sys.argv) == 2:
        problem_list, objective_list = inputs.problem_selection_ogamus_input(input=sys.argv[1])
    elif len(sys.argv) == 1:
        problem_list, objective_list = inputs.problem_selection_ogamus()
    else:
        print("Input a valid PDDL problem file as argument or leave args empty.\n")
        exit()


    # Loop that executes as many times as problems are defined
    iteration = 0
    for problem in problem_list:

        # We create the dictionary to be inserted into the JSON that OGAMUS reads. It contains the scene info previously extracted and the objective
        dictionary = [{
            "episode": 1,
            "scene": "FloorPlan" + scene_number,
            "goal": "(exists (?o1 - " + objective_list[iteration] + ") (and (viewing ?o1) (close_to ?o1)))",
            "agent_position": agent_pos,
            "agent_rotation": agent_rot,
            "initial_orientation": agent_rot['y'],
            "initial_horizon": agent_hor,
            "agent_is_standing": True,
            "agent_in_high_friction_area": False,
            "agent_fov": 79,
            "shortest_path": [
                {
                    "x": -1.0,
                    "y": 0.901863694190979,
                    "z": 2.0
                }
            ],
            "shortest_path_length": 0
        }]

        # Modify json with scene info
        json_object = json.dumps(dictionary, indent=4)
        with open(DATASET, "w") as f:
            f.write(json_object)

        # Call to ogamus to find the objective 
        controller = ogamus.main(controller)

        # Check if OGAMUS has found the objective. If plan has 200 steps -> objective not found.
        with open(LOG, "r") as f:
            log_str = f.read()
            if log_str.find("200:Stop") != -1:
                print(
                    "No se ha encontrado el objetivo indicado tras recorrer la escena durante 200 pasos\n")
                print("Ejecute de nuevo el programa y pruebe con un objetivo distinto\n")
                exit()

        # Call ExecOgamus to execute the action over the objective
        execute = ExecOgamus(controller, problem, objective_list[iteration], iteration)

        # Save facts found from OGAMUS into problems folder
        shutil.copyfile("OGAMUS/Plan/PDDL/facts.pddl",
                        f"pddl/problems/problem{iteration}.pddl")

        # Update agent position in for next OGAMUS execution
        event = controller.step("Pass")
        agent_pos = event.metadata["agent"]["position"]
        agent_rot = event.metadata["agent"]["rotation"]
        agent_hor = event.metadata["agent"]["cameraHorizon"]

        # Update iteration count
        iteration += 1
